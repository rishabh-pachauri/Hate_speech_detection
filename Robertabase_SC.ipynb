{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1CZrZZ43dXRs9lbl8xmQ4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rDbjpsv6BMuB"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","train_df = pd.read_csv(\"HateSpeechDetection.csv\")\n","train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)\n","train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"GlwMmkv_aW93","executionInfo":{"status":"ok","timestamp":1710916092930,"user_tz":-330,"elapsed":751,"user":{"displayName":"RISHABH x","userId":"10942219574920088077"}},"outputId":"05d0cbd6-6549-466d-f634-9aadf7e21b95"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Platform                                               text  target\n","1221  Twitter  Just seems like a roundabout way of saying he ...       0\n","1651  Twitter  but on the bright side im gonna be driving to ...       0\n","1460  Twitter  This girl is not funny. I see her tweets all t...       0\n","1081  Twitter  Is this a pilot for a new comedy  show because...       0\n","1405  Twitter  Yes, but with fashion. I don't know, I have th...       0"],"text/html":["\n","  <div id=\"df-71d88c76-d175-41ee-a419-1e436d56099c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Platform</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1221</th>\n","      <td>Twitter</td>\n","      <td>Just seems like a roundabout way of saying he ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1651</th>\n","      <td>Twitter</td>\n","      <td>but on the bright side im gonna be driving to ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1460</th>\n","      <td>Twitter</td>\n","      <td>This girl is not funny. I see her tweets all t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1081</th>\n","      <td>Twitter</td>\n","      <td>Is this a pilot for a new comedy  show because...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1405</th>\n","      <td>Twitter</td>\n","      <td>Yes, but with fashion. I don't know, I have th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71d88c76-d175-41ee-a419-1e436d56099c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-71d88c76-d175-41ee-a419-1e436d56099c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-71d88c76-d175-41ee-a419-1e436d56099c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3a7480eb-df1a-4c28-80db-d913a298302d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a7480eb-df1a-4c28-80db-d913a298302d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3a7480eb-df1a-4c28-80db-d913a298302d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df","summary":"{\n  \"name\": \"train_df\",\n  \"rows\": 1920,\n  \"fields\": [\n    {\n      \"column\": \"Platform\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Twitter\",\n          \"4Chan\",\n          \"Reddit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1919,\n        \"samples\": [\n          \"I'm getting scoped tomorrow!  I may need to do this.\",\n          \"So I smoked weed almost daily for about 20 years. 16 - 35. And cigarettes until more or less 28. Quit smoking weed last year thanks to my wife. \",\n          \"Kill her before she breeds.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import numpy as np\n","import re\n","import nltk\n","import string\n","\n","class TweetDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer):\n","        texts = dataframe.text.values.tolist()\n","\n","        texts = [self._preprocess(text) for text in texts]\n","\n","        self._print_random_samples(texts)\n","\n","        self.texts = [tokenizer(text, padding='max_length',\n","                                max_length=150,\n","                                truncation=True,\n","                                return_tensors=\"pt\")\n","                      for text in texts]\n","\n","        if 'target' in dataframe:\n","            classes = dataframe.target.values.tolist()\n","            self.labels = classes\n","\n","    def _print_random_samples(self, texts):\n","        np.random.seed(42)\n","        random_entries = np.random.randint(0, len(texts), 5)\n","\n","        for i in random_entries:\n","            print(f\"Entry {i}: {texts[i]}\")\n","\n","        print()\n","\n","    def _preprocess(self, text):\n","        text = self._remove_amp(text)\n","        text = self._remove_links(text)\n","        text = self._remove_hashes(text)\n","        text = self._remove_retweets(text)\n","        text = self._remove_mentions(text)\n","        text = self._remove_multiple_spaces(text)\n","\n","        #text = self._lowercase(text)\n","        text = self._remove_punctuation(text)\n","        #text = self._remove_numbers(text)\n","\n","        text_tokens = self._tokenize(text)\n","        text_tokens = self._stopword_filtering(text_tokens)\n","        #text_tokens = self._stemming(text_tokens)\n","        text = self._stitch_text_tokens_together(text_tokens)\n","\n","        return text.strip()\n","\n","\n","    def _remove_amp(self, text):\n","        return text.replace(\"&amp;\", \" \")\n","\n","    def _remove_mentions(self, text):\n","        return re.sub(r'(@.*?)[\\s]', ' ', text)\n","\n","    def _remove_multiple_spaces(self, text):\n","        return re.sub(r'\\s+', ' ', text)\n","\n","    def _remove_retweets(self, text):\n","        return re.sub(r'^RT[\\s]+', ' ', text)\n","\n","    def _remove_links(self, text):\n","        return re.sub(r'https?:\\/\\/[^\\s\\n\\r]+', ' ', text)\n","\n","    def _remove_hashes(self, text):\n","        return re.sub(r'#', ' ', text)\n","\n","    def _stitch_text_tokens_together(self, text_tokens):\n","        return \" \".join(text_tokens)\n","\n","    def _tokenize(self, text):\n","        return nltk.word_tokenize(text, language=\"english\")\n","\n","    def _stopword_filtering(self, text_tokens):\n","        stop_words = nltk.corpus.stopwords.words('english')\n","\n","        return [token for token in text_tokens if token not in stop_words]\n","\n","    def _stemming(self, text_tokens):\n","        porter = nltk.stem.porter.PorterStemmer()\n","        return [porter.stem(token) for token in text_tokens]\n","\n","    def _remove_numbers(self, text):\n","        return re.sub(r'\\d+', ' ', text)\n","\n","    def _lowercase(self, text):\n","        return text.lower()\n","\n","    def _remove_punctuation(self, text):\n","        return ''.join(character for character in text if character not in string.punctuation)\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","\n","        label = -1\n","        if hasattr(self, 'labels'):\n","            label = self.labels[idx]\n","\n","        return text, label"],"metadata":{"id":"3lP00r9BT06M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","\n","class TweetClassifier(nn.Module):\n","    def __init__(self, base_model):\n","        super(TweetClassifier, self).__init__()\n","\n","        self.bert = base_model\n","        self.fc1 = nn.Linear(768, 32)\n","        self.fc2 = nn.Linear(32, 1)\n","\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_ids, attention_mask):\n","        bert_out = self.bert(input_ids=input_ids,\n","                             attention_mask=attention_mask)[0][:, 0]\n","        x = self.fc1(bert_out)\n","        x = self.relu(x)\n","\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","\n","        return x"],"metadata":{"id":"x6mw6uX8T77r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.optim import Adam\n","from tqdm import tqdm\n","\n","def train(model, train_dataloader, val_dataloader, learning_rate, epochs):\n","    best_val_loss = float('inf')\n","    early_stopping_threshold_count = 0\n","\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.BCELoss()\n","    optimizer = Adam(model.parameters(), lr=learning_rate)\n","\n","    model = model.to(device)\n","    criterion = criterion.to(device)\n","\n","    for epoch in range(epochs):\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        model.train()\n","\n","        for train_input, train_label in tqdm(train_dataloader):\n","            attention_mask = train_input['attention_mask'].to(device)\n","            input_ids = train_input['input_ids'].squeeze(1).to(device)\n","\n","            train_label = train_label.to(device)\n","\n","            output = model(input_ids, attention_mask)\n","\n","            loss = criterion(output, train_label.float().unsqueeze(1))\n","\n","            total_loss_train += loss.item()\n","\n","            acc = ((output >= 0.5).int() == train_label.unsqueeze(1)).sum().item()\n","            total_acc_train += acc\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        with torch.no_grad():\n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            model.eval()\n","\n","            for val_input, val_label in tqdm(val_dataloader):\n","                attention_mask = val_input['attention_mask'].to(device)\n","                input_ids = val_input['input_ids'].squeeze(1).to(device)\n","\n","                val_label = val_label.to(device)\n","\n","                output = model(input_ids, attention_mask)\n","\n","                loss = criterion(output, val_label.float().unsqueeze(1))\n","\n","                total_loss_val += loss.item()\n","\n","                acc = ((output >= 0.5).int() == val_label.unsqueeze(1)).sum().item()\n","                total_acc_val += acc\n","\n","            print(f'Epochs: {epoch + 1} '\n","                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n","                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n","                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n","                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n","\n","            if best_val_loss > total_loss_val:\n","                best_val_loss = total_loss_val\n","                torch.save(model, f\"best_model.pt\")\n","                print(\"Saved model\")\n","                early_stopping_threshold_count = 0\n","            else:\n","                early_stopping_threshold_count += 1\n","\n","            if early_stopping_threshold_count >= 1:\n","                print(\"Early stopping\")\n","                break"],"metadata":{"id":"IJtu9gzMCTo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuLueJmca5Gf","executionInfo":{"status":"ok","timestamp":1710916092931,"user_tz":-330,"elapsed":4,"user":{"displayName":"RISHABH x","userId":"10942219574920088077"}},"outputId":"e0437fdd-1ef8-40cc-f441-e217e4898bc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import DataLoader\n","\n","torch.manual_seed(0)\n","np.random.seed(0)\n","\n","\n","BERT_MODEL = \"roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n","base_model = AutoModel.from_pretrained(BERT_MODEL)\n","\n","train_dataloader = DataLoader(TweetDataset(train_df, tokenizer), batch_size=8, shuffle=True, num_workers=0)\n","val_dataloader = DataLoader(TweetDataset(val_df, tokenizer), batch_size=8, num_workers=0)\n","\n","model = TweetClassifier(base_model)\n","\n","\n","learning_rate = 1e-5\n","epochs = 5\n","train(model, train_dataloader, val_dataloader, learning_rate, epochs)"],"metadata":{"id":"Zwvmu-VGCYQq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11e49e1b-bd71-45c3-dd35-a008b1a80fd1","executionInfo":{"status":"ok","timestamp":1710926044559,"user_tz":-330,"elapsed":3297280,"user":{"displayName":"RISHABH x","userId":"10942219574920088077"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Entry 1126: I told facial expressions I pull meetings want know vibe Im walking term\n","Entry 1459: Have good day u black monkey ape nigger\n","Entry 860: The I listen DMN ’ stuff I like lazy favorite track I enjoy reverby guitar\n","Entry 1294: best hope states secede union engage compacts states well\n","Entry 1130: You sure towelhead\n","\n","Entry 102: Oh aint Muslim Arab You dont even want claim people But I get aint nobody want claim dirty ass towelhead terrorist anyway\n","Entry 435: didnt get take shit morning\n","Entry 348: For record faggot bastard paid people lock mother outside estate chat power chain residence gate insideow\n","Entry 270: This nigga fucking retard whore And I knew Always trust instincts\n","Entry 106: Thanks anon\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 240/240 [51:28<00:00, 12.87s/it]\n","100%|██████████| 60/60 [03:54<00:00,  3.91s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 1 | Train Loss:  0.318 | Train Accuracy:  0.873 | Val Loss:  0.266 | Val Accuracy:  0.894\n","Saved model\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 240/240 [50:58<00:00, 12.74s/it]\n","100%|██████████| 60/60 [03:54<00:00,  3.91s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 2 | Train Loss:  0.128 | Train Accuracy:  0.963 | Val Loss:  0.148 | Val Accuracy:  0.956\n","Saved model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [51:23<00:00, 12.85s/it]\n","100%|██████████| 60/60 [03:56<00:00,  3.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.074 | Train Accuracy:  0.984 | Val Loss:  0.154 | Val Accuracy:  0.956\n","Early stopping\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def get_text_predictions(model, loader):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    model = model.to(device)\n","\n","\n","    results_predictions = []\n","    with torch.no_grad():\n","        model.eval()\n","        for data_input, _ in tqdm(loader):\n","            attention_mask = data_input['attention_mask'].to(device)\n","            input_ids = data_input['input_ids'].squeeze(1).to(device)\n","\n","\n","            output = model(input_ids, attention_mask)\n","\n","            output = (output > 0.5).int()\n","            results_predictions.append(output)\n","\n","    return torch.cat(results_predictions).cpu().detach().numpy()"],"metadata":{"id":"yDOka0IQCcOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.load(\"best_model.pt\")\n","\n","test_dataloader = DataLoader(TweetDataset(test_df, tokenizer),\n","\tbatch_size=8, shuffle=False, num_workers=0)\n","\n","sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n","\n","sample_submission[\"target\"] = get_text_predictions(model, test_dataloader)\n","\n","display(sample_submission.head(20))\n","\n","sample_submission.to_csv(\"submission.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cztRTyWj783","executionInfo":{"status":"error","timestamp":1710926047182,"user_tz":-330,"elapsed":2624,"user":{"displayName":"RISHABH x","userId":"10942219574920088077"}},"outputId":"f9d8bfb0-5ff0-4954-aed9-3cac2d52efd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entry 102: Dont take random advice internet\n","Entry 435: fousey youre faggot Sad see become\n","Entry 270: Theres still lot complexity functionality missing But sure looks like important stepping stone towards\n","Entry 106: Someone explain tranny isnt mental illness cos mental hospitals looking full soon\n","Entry 71: Disgusting muslims Imagine smell\n","\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/nlp-getting-started/sample_submission.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f0c8b0d153f9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \tbatch_size=8, shuffle=False, num_workers=0)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/nlp-getting-started/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/nlp-getting-started/sample_submission.csv'"]}]}]}